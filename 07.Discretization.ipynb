{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Discretization (Binning) with Feature-engine\n",
    "\n",
    "This notebook demonstrates various techniques for discretization (binning) of continuous variables using the `feature_engine` library in Python.\n",
    "\n",
    "## 1. Import Libraries\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from feature_engine.discretisation import (\n",
    "    EqualWidthDiscretiser, \n",
    "    EqualFrequencyDiscretiser, \n",
    "    DecisionTreeDiscretiser,\n",
    "    ArbitraryDiscretiser\n",
    ")\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "```\n",
    "\n",
    "## 2. Load Data\n",
    "\n",
    "We'll use a synthetic dataset that includes continuous variables suitable for discretization.\n",
    "\n",
    "```python\n",
    "# Create a sample dataset\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'Age': [22, 25, 47, 52, 46, 56, 24, 27, 30, 45, 57, 60],\n",
    "    'Income': [25000, 27000, 55000, 60000, 52000, 70000, 28000, 30000, 35000, 50000, 72000, 75000],\n",
    "    'Years_of_Experience': [1, 2, 5, 8, 7, 10, 2, 3, 4, 6, 9, 12]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Initial Dataset with Continuous Variables:\")\n",
    "df.head(10)\n",
    "```\n",
    "\n",
    "## 3. Split Data into Training and Testing Sets\n",
    "\n",
    "```python\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "print(\"Training Set:\")\n",
    "X_train.head()\n",
    "```\n",
    "\n",
    "## 4. Understanding Discretization\n",
    "\n",
    "Discretization, also known as binning, is the process of transforming continuous variables into discrete buckets or intervals. This process can help improve model interpretability, reduce the impact of outliers, and handle skewed distributions. Discretization can be especially useful when the relationship between a continuous variable and the target variable is non-linear or when certain ranges of the variable have distinct impacts.\n",
    "\n",
    "## 5. Discretization Techniques\n",
    "\n",
    "### 5.1 Equal-Width Discretization\n",
    "\n",
    "**Explanation:**  \n",
    "Equal-width discretization divides the range of the variable into intervals of equal width. This method is straightforward and easy to interpret, but it may not capture the underlying distribution of the data effectively, especially if the data is skewed.\n",
    "\n",
    "**Implementation:**\n",
    "\n",
    "```python\n",
    "# Apply Equal-Width Discretization\n",
    "ewd = EqualWidthDiscretiser(bins=4, variables=['Age', 'Income'])\n",
    "X_train_ewd = ewd.fit_transform(X_train)\n",
    "print(\"Dataset after Equal-Width Discretization:\")\n",
    "X_train_ewd.head()\n",
    "```\n",
    "\n",
    "### 5.2 Equal-Frequency Discretization\n",
    "\n",
    "**Explanation:**  \n",
    "Equal-frequency discretization divides the variable into intervals that contain approximately the same number of observations. This method is useful for capturing the distribution of the data, especially in skewed distributions, but it may result in intervals of varying widths.\n",
    "\n",
    "**Implementation:**\n",
    "\n",
    "```python\n",
    "# Apply Equal-Frequency Discretization\n",
    "efd = EqualFrequencyDiscretiser(q=4, variables=['Age', 'Income'])\n",
    "X_train_efd = efd.fit_transform(X_train)\n",
    "print(\"Dataset after Equal-Frequency Discretization:\")\n",
    "X_train_efd.head()\n",
    "```\n",
    "\n",
    "### 5.3 Decision Tree Discretization\n",
    "\n",
    "**Explanation:**  \n",
    "Decision tree discretization uses a decision tree to determine the optimal split points based on the relationship between the continuous variable and the target variable. This method can effectively capture non-linear relationships and create meaningful bins, but it requires a target variable for supervision.\n",
    "\n",
    "**Implementation:**\n",
    "\n",
    "```python\n",
    "# Assume we have a target variable\n",
    "X_train['target'] = [0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1]\n",
    "\n",
    "# Apply Decision Tree Discretization\n",
    "dtd = DecisionTreeDiscretiser(cv=3, scoring='accuracy', variables=['Age', 'Income'])\n",
    "X_train_dtd = dtd.fit_transform(X_train, X_train['target'])\n",
    "print(\"Dataset after Decision Tree Discretization:\")\n",
    "X_train_dtd.head()\n",
    "```\n",
    "\n",
    "### 5.4 Arbitrary Discretization\n",
    "\n",
    "**Explanation:**  \n",
    "Arbitrary discretization allows the user to manually specify the bin edges. This method is useful when domain knowledge suggests specific thresholds or when specific ranges of the variable are known to have distinct meanings.\n",
    "\n",
    "**Implementation:**\n",
    "\n",
    "```python\n",
    "# Specify custom bin edges\n",
    "arbitrary_binner = ArbitraryDiscretiser(binning_dict={\n",
    "    'Age': [20, 30, 40, 50, 60],\n",
    "    'Income': [25000, 35000, 50000, 70000, 80000]\n",
    "})\n",
    "X_train_arbitrary = arbitrary_binner.fit_transform(X_train)\n",
    "print(\"Dataset after Arbitrary Discretization:\")\n",
    "X_train_arbitrary.head()\n",
    "```\n",
    "\n",
    "## 6. Conclusion\n",
    "\n",
    "Discretization can significantly impact the performance and interpretability of machine learning models. The method you choose depends on the specific characteristics of your data and the problem you're trying to solve.\n",
    "\n",
    "- **Equal-width discretization** is simple and interpretable but may not capture data distribution well.\n",
    "- **Equal-frequency discretization** ensures that bins have similar numbers of observations, which can be beneficial for skewed data.\n",
    "- **Decision tree discretization** is powerful for capturing complex relationships but requires a target variable.\n",
    "- **Arbitrary discretization** offers flexibility when specific thresholds are meaningful based on domain knowledge.\n",
    "\n",
    "```python\n",
    "# Save the final dataset after discretization\n",
    "X_train_arbitrary.to_csv('discretized_dataset.csv', index=False)\n",
    "```\n",
    "\n",
    "You can run this notebook step by step to see how each discretization method works and how it impacts the dataset. Discretization is a crucial step in many machine learning workflows, especially when dealing with non-linear relationships and improving model interpretability."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
